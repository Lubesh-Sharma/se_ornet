Jitting Chamfer 3D
Global seed set to 42
/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 Tesla P100-PCIE-16GB which is of cuda capability 6.0.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (7.0) - (12.0)
    
  warnings.warn(
/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/torch/cuda/__init__.py:304: UserWarning: 
    Please install PyTorch with a following CUDA
    configurations:  12.6 following instructions at
    https://pytorch.org/get-started/locally/
    
  warnings.warn(matched_cuda_warn.format(matched_arches))
/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/torch/cuda/__init__.py:326: UserWarning: 
Tesla P100-PCIE-16GB with CUDA capability sm_60 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.
If you want to use the Tesla P100-PCIE-16GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(
/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/utilities/device_parser.py:135: LightningDeprecationWarning: Parsing of the Trainer argument gpus='0' (string) will change in the future. In the current version of Lightning, this will select CUDA device with index 0, but from v1.5 it will select gpus [] (same as gpus=0 (int)).
  rank_zero_deprecation(
/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:110: LightningDeprecationWarning: `Trainer(distributed_backend=dp)` has been deprecated and will be removed in v1.5. Use `Trainer(accelerator=dp)` instead.
  rank_zero_deprecation(
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded JIT 3D CUDA chamfer distance
dataset:  surreal

Log directory:
/home/du2/22CS30065/SE-ORNet/output/shape_corr/PointCorrWithAngle/arch_PointCorrWithAngle/dataset_name_surreal/latent_dim_768/04_09:01:41:03




/home/du2/22CS30065/SE-ORNet/output/shape_corr/PointCorrWithAngle/arch_PointCorrWithAngle/dataset_name_surreal/latent_dim_768/04_09:01:41:03



Traceback (most recent call last):
  File "/home/du2/22CS30065/SE-ORNet/train.py", line 109, in <module>
    main_train(model_class_pointer, hparams, parser)
  File "/home/du2/22CS30065/SE-ORNet/train.py", line 81, in main_train
    trainer.fit(model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 553, in fit
    self._run(model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 874, in _run
    self.accelerator.setup(self, model)  # note: this sets up self.lightning_module
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/accelerators/gpu.py", line 42, in setup
    return super().setup(trainer, model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/accelerators/accelerator.py", line 86, in setup
    self.setup_training_type_plugin(model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/accelerators/accelerator.py", line 339, in setup_training_type_plugin
    self.training_type_plugin.setup(model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/plugins/training_type/dp.py", line 54, in setup
    self._model = DataParallel(LightningParallelModule(model), self.parallel_devices)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 169, in __init__
    self.module.to(self.src_device_obj)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py", line 109, in to
    return super().to(*args, **kwargs)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1369, in to
    return self._apply(convert)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 928, in _apply
    module._apply(fn)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/torch/nn/modules/module.py", line 928, in _apply
    module._apply(fn)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/torchmetrics/metric.py", line 489, in _apply
    self._device = fn(torch.zeros(1, device=self.device)).device
torch.AcceleratorError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

