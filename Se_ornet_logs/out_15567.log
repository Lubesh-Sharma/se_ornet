W0904 22:05:17.121000 693338 site-packages/torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0904 22:05:17.121000 693338 site-packages/torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
Jitting Chamfer 3D
Global seed set to 42
/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/utilities/device_parser.py:135: LightningDeprecationWarning: Parsing of the Trainer argument gpus='0' (string) will change in the future. In the current version of Lightning, this will select CUDA device with index 0, but from v1.5 it will select gpus [] (same as gpus=0 (int)).
  rank_zero_deprecation(
/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:110: LightningDeprecationWarning: `Trainer(distributed_backend=dp)` has been deprecated and will be removed in v1.5. Use `Trainer(accelerator=dp)` instead.
  rank_zero_deprecation(
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded JIT 3D CUDA chamfer distance
dataset:  surreal

Log directory:
/home/du2/22CS30065/SE-ORNet/output/shape_corr/PointCorrWithAngle/arch_PointCorrWithAngle/dataset_name_surreal/latent_dim_768/04_09:22:06:01




/home/du2/22CS30065/SE-ORNet/output/shape_corr/PointCorrWithAngle/arch_PointCorrWithAngle/dataset_name_surreal/latent_dim_768/04_09:22:06:01



Traceback (most recent call last):
  File "/home/du2/22CS30065/SE-ORNet/train.py", line 109, in <module>
    main_train(model_class_pointer, hparams, parser)
  File "/home/du2/22CS30065/SE-ORNet/train.py", line 81, in main_train
    trainer.fit(model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 553, in fit
    self._run(model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 874, in _run
    self.accelerator.setup(self, model)  # note: this sets up self.lightning_module
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/accelerators/gpu.py", line 42, in setup
    return super().setup(trainer, model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/accelerators/accelerator.py", line 88, in setup
    self.setup_optimizers(trainer)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/accelerators/accelerator.py", line 330, in setup_optimizers
    optimizers, lr_schedulers, optimizer_frequencies = self.training_type_plugin.init_optimizers(
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 223, in init_optimizers
    return trainer.init_optimizers(model)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/trainer/optimizers.py", line 99, in init_optimizers
    lr_schedulers = self.configure_schedulers(lr_schedulers, monitor, is_manual_optimization)
  File "/home/du2/22CS30065/miniconda3/envs/se_ornet/lib/python3.10/site-packages/pytorch_lightning/trainer/optimizers.py", line 176, in configure_schedulers
    raise ValueError(f'The provided lr scheduler "{scheduler}" is invalid')
ValueError: The provided lr scheduler "<torch.optim.lr_scheduler.MultiStepLR object at 0x7a5e0f367fa0>" is invalid
